[["diskrete-wahrscheinlichkeitsverteilungen.html", "Chapter 4 Diskrete Wahrscheinlichkeitsverteilungen 4.1 Wahrscheinlichkeitsverteilungen in R 4.2 Bernoulli-Verteilung 4.3 Binominalverteilung 4.4 Geometrische Verteilung", " Chapter 4 Diskrete Wahrscheinlichkeitsverteilungen Eine Wahrscheinlichkeitsverteilung heißt eine diskrete Wahrscheinlichkeitsverteilung, wenn einer der folgenden drei Fälle gilt: Sie ist auf einer endlichen Menge definiert (\\({\\displaystyle \\{0,1,2,\\dots ,n\\}})\\). Sie ist auf einer abzählbar unendlichen Menge definiert (meist die natürlichen Zahlen \\(\\mathbb{N}\\) ). Sie ist auf einer beliebigen Menge definiert, nimmt aber nur auf höchstens abzählbar vielen Elementen dieser Menge einen positiven Wert an. Das bedeutet, es existiert eine höchstens abzählbare Menge \\(M\\) mit \\({\\displaystyle P(M)=1}\\) (meist die natürlichen Zahlen, eingebettet in die reellen Zahlen). 4.1 Wahrscheinlichkeitsverteilungen in R R nutzt standatisierte Präfixe, um verschiedene Verteilungseigenschaften abzufragen: Präfix Bedeutung Math. Ausdruck d Zähldiche (PMF) bzw. Wahrscheinlichkeitsdichte (PDF) \\(P(X=x)\\) p Verteilungsfunktion (CDF) \\(P(X \\leq x)\\) q Quantilsfunktion Given \\(p\\), the smallest \\(x\\) such that \\(P(X\\leq x) &gt; p\\) r Ziehen aus gegebener Verteilung n:= Anzahl der Ziehungen q gibt also die Umkehrfunktion der CDF (\\(P(X\\leq x)\\)) und damit für eine entsprechende Wahrscheinlichkeit \\(p\\) dasjenige \\(x\\), sodass die Wkt., dass \\(X\\leq x\\) gleich \\(p\\) ist. 4.2 Bernoulli-Verteilung Zufallsgrößen mit einer Bernoulli-Verteilung (auch Null-Eins-Verteilung, Boole-Verteilung) nutzt man zur Beschreibung von zufälligen Ereignissen, bei denen es nur zwei mögliche Versuchsausgänge (Erfolg/Misserfolg) gibt. Die zugehörige Wahrscheinlichkeit \\(p\\) für einen Erfolg nennt man Erfolgswahrscheinlichkeit und \\(q = 1 − p\\) die Wahrscheinlichkeit eines Misserfolgs. Bernoulli-Verteilung Definition Eine diskrete Zufallsgröße \\(X\\) mit Werten in der Menge \\(\\{0,1\\}\\) unterliegt der Null-Eins-Verteilung mit dem Parameter \\(p\\in [0,1]\\), wenn sie der folgenden Wahrscheinlichkeitsfunktion folgt: \\[ {\\displaystyle f(x\\mid p)={\\begin{cases}p^{x}(1-p)^{1-x}&amp;{\\text{falls}}\\quad x=0,1\\\\0&amp;{\\text{sonst.}}\\end{cases}}} \\] Verteilungsfunktion \\[{\\displaystyle F_{X}(x)={\\begin{cases}0&amp;{\\text{ falls }}\\quad x&lt;0\\\\1-p&amp;{\\text{ falls }}\\quad 0\\leq x&lt;1\\\\1&amp;{\\text{ falls }}\\quad x\\geq 1\\end{cases}}}.\\] Erwartungswert \\[{E}\\left(X\\right)=p\\] Varianz \\[{V}\\left(X\\right)=pq\\] Beispiel 1 Werfen einer Münze: Kopf (Erfolg), \\(p=1/2\\), und Zahl (Misserfolg), \\(q=1/2\\). Beispiel 2 Werfen eines Würfels, wobei nur eine „6“ als Erfolg gewertet wird: \\(p=1/6\\), \\(q=5/6\\). Man schreibt dann \\({\\displaystyle X\\sim {\\mathcal {B}}(p)}\\) oder \\(X\\sim Ber_{p}\\). Eine Reihe von unabhängigen identischen Versuchen, bei der jeder Einzelversuch der Bernoulli-Verteilung genügt, wird Bernoulli-Prozess oder bernoullisches Versuchsschema genannt. 4.3 Binominalverteilung Die Binomialverteilung beschreibt die Anzahl der Erfolge in einem Bernoulli-Prozess, also einer Serie von gleichartigen und unabhängigen Versuchen, die jeweils genau zwei mögliche Ergebnisse haben („Erfolg“ oder „Misserfolg“). 4.4 Geometrische Verteilung Werden nacheinander unabhängige Bernoulli-Experimente durchgeführt, d.h. es gibt die Versuchsausgänge \\(1\\) (Erfolg, z.B. Kopf) und \\(0\\) (Missverfolg, z.B. Zahl), dann ordnet die geometrische Verteilung entweder Variante A: der Anzahl \\(X\\) der Bernoulli-Versuche, bis zum ersten Erfolg (definiert auf der Menge \\(\\mathbb {N}\\)), bzw. Variante B: der Anzahl \\(Y\\) der Fehlversuche vor dem ersten Erfolg (definiert auf der Menge \\(\\mathbb {N} _{0}\\)) Wahrscheinlichkeiten zu. Theoretisch können dabei unendlich viele Bernoulli-Experimente nötig sein. Die beiden Varianten stehen in der Beziehung \\(X=Y+1\\). Da die Experimente unabhängig sind, müssen damit \\(P(X=n)\\) alle Versuche vor dem \\(n\\)-ten Versuch müssen gescheitert sein und der \\(n\\)-te Versuch muss erfolgreich gewesen sein. Die Wahrscheinlichkeitsfunktion ist demanach \\(P(X=n) = (1-p)^{n-1} p\\) . Geometrische Verteilung Definition / Verteilungsfunktion \\(X \\sim G(p)\\) , wenn für die Wahrscheinlichkeit, dass man genau \\(n\\) Versuche benötigt, um zum ersten Erfolg zu kommen, gilt \\[{\\displaystyle \\operatorname {P} (X=n)=p(1-p)^{n-1}},\\] bzw. \\(Y \\sim G(p)\\), wenn für die Wahrscheinlichkeit, \\(n\\) Fehlversuche vor dem ersten Erfolg zu haben, gilt \\[\\operatorname {P}(Y=n)=p(1-p)^{{n}}, \\;n=0,1,2,\\dotsc .\\] Verteilungsfunktion (A) \\[{\\displaystyle \\operatorname {P} (X\\leq n)=1-q^{n}=1-(1-p)^{n}}\\] Verteilungsfunktion (B) \\[{\\displaystyle \\operatorname {P} (Y\\leq n)=1-q^{n+1}=1-(1-p)^{n+1}}\\] Erwartungswert (A) \\[\\operatorname {E}(X)={\\frac {1}{p}}\\] Erwartungswert (B) \\[\\operatorname {E}(Y)=\\operatorname {E}(X)-1={\\frac {1-p}{p}}\\] Varianz \\[\\operatorname {Var}(X)=\\operatorname {Var}(Y)={\\frac {1-p}{p^{2}}}={\\frac {1}{p^{{2}}}}-{\\frac {1}{p}}\\] Gedächtnislosigkeit: Die geometrische Verteilung ist eine gedächtnislose Verteilung, d. h., es gilt für Variante A: \\(\\operatorname {P}(X=n+k\\,|\\,X&gt;n)=\\operatorname {P}(X=k)\\quad n,k=1,2,\\dotsc\\) Variante B: \\(\\operatorname {P}(Y=n+k\\,|\\,Y\\geq n)=\\operatorname {P}(Y=k)\\quad n,k=0,1,2,\\dotsc\\) Ist also von einer geometrisch verteilten Zufallsvariablen bekannt, dass sie größer als der Wert \\(n\\) ist (Variante A) bzw. mindestens den Wert \\(n\\) hat (Variante B), so ist die Wahrscheinlichkeit, dass sie diesen Wert um \\(k\\) übertrifft, genau so groß wie die, dass eine identische Zufallsvariable überhaupt den Wert \\(k\\) annimmt. Die Gedächtnislosigkeit ist eine definierende Eigenschaft; die geometrische Verteilung ist also die einzig mögliche gedächtnislose diskrete Verteilung. Ihr stetiges Pendant hierbei ist die Exponentialverteilung (5.1). 4.4.1 R: Zähldichte (probability mass function) Beispiel: Wie oft muss ich beim Mensch-ärgere-dich-nicht-Spiel auf die erste Sechs warten? Die Wahrscheinlichkeit, dass ich genau 4 Versuche benötige (\\(P(X=4)\\)) bzw. 3 Mal warten muss (d.h. 3 Misserfolg habe, \\(P(Y=3)\\)), ist: dgeom(x = 3, prob = 1/6, log = FALSE) ## [1] 0.09645062 Entsprechend ergibt sich für die Anzahl der Misserfolge/Würfe vor dem ersten Erfolg bzw. die Wartenzeit im Bereich \\([0, 12]\\) dann folgende Zähldiche bzw. probability mass function (PMF): x &lt;- 0:12 # Choose the sample space (here, it&#39;s 0,1,2,...,10) p_x &lt;- dgeom(x = x, prob = 1/6) # Compute the shape of the distribution plot(x, p_x, type=&quot;h&quot;, xlim=c(0,12), ylim=c(0,max(p_x)), # Plot the Geometric probability dist lwd = 8, col = &quot;blue&quot;,ylab = &quot;P (Y = n)&quot;, xlab = &quot;n&quot;) Figure 4.1: Zähldichte der geometrischen Verteilung. 4.4.2 R: Verteilungsfunktion (CDF) Um nun die Wahrscheinlichkeit für höchstens drei Misserfolge vor dem ersten Erflog zu finden – also dafür spätestens beim vierten Mal die \\(6\\) zu erhalten – benötigt man die Verteilungsfunktion bzw. CDF: pgeom(q = 3, prob = 1/6) ## [1] 0.5177469 Entsprechend ergibt sich für die Wahrscheinlichekiten, dass die Wartezeit kleiner bzw. gleich \\(0, 1, ...\\) (\\(P(Y\\leq n)\\)) ist dann folgende CDF: x &lt;- 0:12 # choose the sample space (here, it&#39;s 0,1,2,...,10) Fx &lt;- pgeom(q = x, prob = 1/6) # compute the shape of the distribution n &lt;- length(x) plot(x = NA, y = NA, pch = NA, xlim = c(0, max(x)), ylim = c(0, 1), xlab = &quot;n&quot;, ylab = &quot;P (Y &lt;= n)&quot;) points(x = x[-n], y = Fx[-n], pch=19, col = &quot;blue&quot;) points(x = x[-1], y = Fx[-n], pch=1, col = &quot;blue&quot;) for(i in 1:(n-1)) points(x=x[i+0:1], y=Fx[c(i,i)], type=&quot;l&quot;, col = &quot;blue&quot;) Figure 4.2: Verteilungsfunktion (CDF) der geometrischen Verteilung. "]]
